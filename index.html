<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Coen Molyneaux | Portfolio</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
    <img src="assets/profile.jpg" alt="Profile" class="profile-pic">
    <h1>Coen Molyneaux</h1>
    <p>Engineering Physics Student</p>
    <nav>
      <a href="#about">About</a>
      <a href="#projects">Projects</a>
      <a href="#contact">Contact</a>
      <a href="coursework.html">Coursework</a>
    </nav>
  </header>

  <section id="about">
    <h2>About Me</h2>
    <p>
        I'm an Engineering Physics student at the University of British Columbia, currently in my third year of study.
        Recently, I've developed an interest in applying machine learning to the oil and gas industry, something that 
        stemmed from my co-op experience at Condor Energies.
    </p>
  </section>

  <section id="projects">
    <h2>Projects</h2>

    <div class="project">
        <h3>Pet Rescue: Autonomous Robot (Summer 2025)</h3>

        <p>
          My ENPH 253 team (<a class="links" href="https://www.linkedin.com/in/luca-jones1/">Luca Jones</a>,
          <a class="links" href="https://www.linkedin.com/in/harchetan-chohan-504557327/">Harchetan Chohan</a>,
          <a class="links" href="https://www.linkedin.com/in/taichikamei/">Taichi Kamei</a>)
          designed and built an autonomous rescue robot capable of navigating a complex obstacle course,
          identifying and retrieving ‚Äúpet‚Äù targets, and returning them safely to the home zone, all without human control.
        </p>
        
        <p>
          The brain of our robot was an <strong>ESP32 microcontroller</strong>, chosen for its power and versatility.
          A custom state machine was built to manage the various modes of operation such as line following and pet detection.
        </p>
        
        <p>
          The navigation of the robot relies on infrared LEDs and phototransistors to detect the line of electrical tape
          that traces throughout the entire course. By reading which phototransistors are on or off, the robot can determine
          its relative position to the line and make adjustments using <strong>PID control</strong> to stay on course.
        </p>
        
        <p>
          To identify and rescue the pets, our robot utilizes <strong>2D time-of-flight sensors</strong>
          to detect the presence of pet targets. To grab the pets, our robot uses a custom
          <strong>planar 2-bar linkage arm</strong> and a <strong>4-bar claw</strong> to pick up the pet and store it
          in the bucket on board the robot. The arm and claw were built using
          <strong>3D printing</strong>, <strong>laser cutting</strong>, and <strong>water-jet cutting</strong>.
        </p>
        
        <p>
          To lift the bucket and hook it to the zipline, we designed a
          <strong>continuous cascade mechanism</strong> that uses a DC motor to wind a rope around a spool,
          lifting the bucket vertically.
        </p>
        
        <p class="links">
            <a href="https://github.com/Luca-Jones/enph-253-pet-rescue">GitHub Repo</a> |
            <a href="https://youtu.be/9oEp3KTkgeU">Watch It in Action</a> |
            <a href="https://www.cbc.ca/player/play/video/9.6862226">News Article</a>
        </p>        
    </div>

    <div class="project">
        <p>
            <h3> Document Translator (Winter 2025)</h3>
            During my coop at Condor Energies, I developed a pipleine that automates the process of translating documents from Uzbek, Russian
            and Kazakh to English. For this project I had to handle a wide variety of document types such as scanned PDFs, Word, Excel and PowerPoint files. Each had 
            its own challenges when it came to extracting text as well as writing the translated text back into the original format.
        </p>

        <p>
            <h4> Scanned PDFs </h4>
            This involved using Optical Character Recognition (OCR) to extract text from scanned documents such as old
            drilling reports and well logs. Then using the Google translate API to translate the extracted text before
            finally writing the translated text back into a new PDF that closely resembled the original document. A particular challenge
            with this task was ensuring the formatting and layout of the original document was preserved in the translated version. For most PDFs
            I was dealing with they were scanned documents, so in order to write the translated text back to the PDF I had to 'remember' the pixel
            location of each word in the original document and then write the translated text back to those same locations. 

            Here is a first attempt at writing translated text back to a scanned PDF (blurred for confidentiality):

            <img src="assets/first_attempt_ocr.png">

            After a lot more iteration I was able to get much better results that preserved the original formatting and layout of the document (again blurred for confidentiality):
            <img src="assets/second_attempt_ocr.png">

        </p>



    </div>
  </section>

  <section id="Contact">
    <h2>Contact Me</h2>
    <p>
    If you'd like to get in touch, feel free to reach out via email or connect with me on LinkedIn!
    </p>

    <p class="links">
        <a href="mailto:coen.molyneaux@shaw.ca">Email</a> ‚úâÔ∏è | 
        <a href="https://github.com/Coen-Molyneaux">Github</a> üñ•Ô∏è|
        <a href="www.linkedin.com/in/coenmolyneaux">LinkedIn</a> ‚òïÔ∏è
    </p>
   </section>
  </section>


  <footer>
    <p>¬© 2025 Coen Molyneaux.</p>
  </footer>

  <script>
    document.querySelectorAll('.links a').forEach(link => {
      link.setAttribute('target', '_blank');
      link.setAttribute('rel', 'noopener noreferrer');
    });
  </script>
</body>
</html>
